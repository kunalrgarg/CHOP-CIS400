{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project path = /home/guerramarj/github/scosy\n",
      "data path = /home/guerramarj/github/scosy/dataset\n",
      "model path = /home/guerramarj/github/scosy/models\n",
      "embedding path = /home/guerramarj/github/scosy/embedding\n",
      "sys.path = ['', '/cm/shared/easybuild/software/EasyBuild/3.8.1/lib/python2.7/site-packages/vsc_install-0.11.3-py2.7.egg', '/cm/shared/easybuild/software/EasyBuild/3.8.1/lib/python2.7/site-packages/vsc_base-2.8.3-py2.7.egg', '/cm/shared/easybuild/software/EasyBuild/3.8.1/lib/python2.7/site-packages/easybuild_framework-3.8.1-py2.7.egg', '/cm/shared/easybuild/software/EasyBuild/3.8.1/lib/python2.7/site-packages/easybuild_easyblocks-3.8.1-py2.7.egg', '/cm/shared/easybuild/software/EasyBuild/3.8.1/lib/python2.7/site-packages/easybuild_easyconfigs-3.8.1-py2.7.egg', '/cm/shared/easybuild/software/EasyBuild/3.8.1/lib/python2.7/site-packages', '/home/guerramarj/packages/anaconda3/envs/nlp/lib/python36.zip', '/home/guerramarj/packages/anaconda3/envs/nlp/lib/python3.6', '/home/guerramarj/packages/anaconda3/envs/nlp/lib/python3.6/lib-dynload', '/home/guerramarj/packages/anaconda3/envs/nlp/lib/python3.6/site-packages', '/home/guerramarj/packages/anaconda3/envs/nlp/lib/python3.6/site-packages/IPython/extensions', '/home/guerramarj/.ipython', '/home/guerramarj/github/scosy', '/home/guerramarj/github/scosy/utils', '/home/guerramarj/github/scosy/src']\n"
     ]
    }
   ],
   "source": [
    "project_name = 'scosy'\n",
    "# notebook meant to be under ../scosy/notebookts/pubmed.ipynb\n",
    "project_path = Path(os.getcwd()).parent\n",
    "template_path = Path(project_path, 'template')\n",
    "similarities_path = Path(data_path, 'similarities')\n",
    "data_path = Path(project_path, 'dataset')\n",
    "\n",
    "# including the project folder and the utils folder\n",
    "if str(project_path) not in ''.join(sys.path):\n",
    "    sys.path.extend([str(project_path)])\n",
    "\n",
    "print('project path = {0}'.format(project_path))\n",
    "print('data path = {0}'.format(data_path))\n",
    "print('sys.path = {0}'.format(sys.path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "# pubmed\n",
    "from utils.parse import parse\n",
    "from Bio import Entrez\n",
    "# processing mesh treee hierarchy\n",
    "import re\n",
    "# flatten list\n",
    "from functools import reduce\n",
    "from operator import iconcat\n",
    "# nlp\n",
    "from nltk.tokenize import word_tokenize \n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = Path(template_path, '2019New_Mesh_Tree_Hierarchy.txt')\n",
    "mesh_description_dict = dict()\n",
    "with filename.open('r') as tree_file:\n",
    "    header = ''\n",
    "    for line_ix, line in enumerate(tree_file):\n",
    "            if line_ix == 0:\n",
    "                header = line\n",
    "            # '\\n' -> empty line\n",
    "            # 'TREE_NUMBER    DESCRIPTOR' -> header line\n",
    "            # '-------------------------' -> visual line\n",
    "            if line != '\\n' and line != header and '----' not in line:\n",
    "                # subtitute 2 or more spaces by a comma and\n",
    "                # remove last comma if it appears\n",
    "                line = re.sub('[\\s]{2,}', ',', line).rstrip(',')\n",
    "                tree_num_desc = line.split(',')\n",
    "                # this is done for keys with len > 50 (special cases)\n",
    "                value = tree_num_desc[0]\n",
    "                key = ' '.join(tree_num_desc[1:])\n",
    "                key.replace('  ', '')\n",
    "                mesh_description_dict[key.lower()] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = Path(data_path, 'results.xml')\n",
    "records_handle = data_file.open()\n",
    "fetch_records = parse(handle=records_handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contains all the metadata elements on the paper level: PubMed unique Identifier number(PMID), Title, Abstract,\n",
    "# Year, Month, AuthorList, SubjectList, date\n",
    "paper_df = pd.DataFrame(columns=['pmid', 'title', 'abstract', 'mesh'])\n",
    "\n",
    "for record in fetch_records:\n",
    "\n",
    "    pmid = record.get('PMID')\n",
    "    title = record.get('TI')\n",
    "    abstract = record.get('AB')\n",
    "    mesh_term = record.get('MH')\n",
    "    \n",
    "    if pmid and abstract:\n",
    "        \n",
    "        if mesh_term and len(mesh_term) > 1:\n",
    "            # divide all the mesh with multiple term\n",
    "            mesh_term = [x.replace('*', '').lower().split('/')for x in mesh_term]\n",
    "            # flatten the list\n",
    "            mesh_term = reduce(iconcat, mesh_term, [])\n",
    "\n",
    "        row = pd.DataFrame([[pmid, title, abstract, mesh_term]],\n",
    "                           columns=['pmid', 'title', 'abstract', 'mesh'])\n",
    "        paper_df = paper_df.append(row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_df.to_csv(Path(data_path, 'pmid_title_abstract_mesh.csv'),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pmid</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>mesh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30500988</td>\n",
       "      <td>Early Post-Intensive Care Syndrome among Older...</td>\n",
       "      <td>BACKGROUND/OBJECTIVES: New or worsened disabil...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30500532</td>\n",
       "      <td>Revitalizing Aging Skin through Diet.</td>\n",
       "      <td>Mechanisms underlying aging of the skin dermis...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30499797</td>\n",
       "      <td>A Partially Structured Postoperative Handoff P...</td>\n",
       "      <td>OBJECTIVE: To assess the effectiveness of stan...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30499597</td>\n",
       "      <td>Automated data extraction and ensemble methods...</td>\n",
       "      <td>PURPOSE: To compare the effectiveness of ensem...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30499112</td>\n",
       "      <td>Modeling Epidermal Growth Factor Inhibitor-Med...</td>\n",
       "      <td>We have demonstrated that lung sparing surgery...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pmid                                              title  \\\n",
       "0  30500988  Early Post-Intensive Care Syndrome among Older...   \n",
       "1  30500532              Revitalizing Aging Skin through Diet.   \n",
       "2  30499797  A Partially Structured Postoperative Handoff P...   \n",
       "3  30499597  Automated data extraction and ensemble methods...   \n",
       "4  30499112  Modeling Epidermal Growth Factor Inhibitor-Med...   \n",
       "\n",
       "                                            abstract  mesh  \n",
       "0  BACKGROUND/OBJECTIVES: New or worsened disabil...  None  \n",
       "1  Mechanisms underlying aging of the skin dermis...  None  \n",
       "2  OBJECTIVE: To assess the effectiveness of stan...  None  \n",
       "3  PURPOSE: To compare the effectiveness of ensem...  None  \n",
       "4  We have demonstrated that lung sparing surgery...  None  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = paper_df['title'].astype(str) + paper_df['abstract'].astype(str) + paper_df['mesh'].astype(str)\n",
    "text = [x.replace('None', '') for x in text]\n",
    "text = pd.DataFrame({'pmid': paper_df.pmid, 'text':text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "text.to_csv(Path(data_path, 'pmid_text.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pmid</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30500988</td>\n",
       "      <td>Early Post-Intensive Care Syndrome among Older...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30500532</td>\n",
       "      <td>Revitalizing Aging Skin through Diet.Mechanism...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30499797</td>\n",
       "      <td>A Partially Structured Postoperative Handoff P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30499597</td>\n",
       "      <td>Automated data extraction and ensemble methods...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30499112</td>\n",
       "      <td>Modeling Epidermal Growth Factor Inhibitor-Med...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pmid                                               text\n",
       "0  30500988  Early Post-Intensive Care Syndrome among Older...\n",
       "1  30500532  Revitalizing Aging Skin through Diet.Mechanism...\n",
       "2  30499797  A Partially Structured Postoperative Handoff P...\n",
       "3  30499597  Automated data extraction and ensemble methods...\n",
       "4  30499112  Modeling Epidermal Growth Factor Inhibitor-Med..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_documents = pd.read_csv(Path(data_path, 'pmid_text.csv'))\n",
    "raw_documents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['early', 'post-intensive', 'care', 'syndrome', 'among', 'older', 'adult', 'sepsis', 'survivors', 'receiving', 'home', 'care.background/objectives', ':', 'new', 'or', 'worsened', 'disabilities', 'in', 'functional', ',', 'cognitive', ',', 'or', 'mental', 'health', 'following', 'an', 'intensive', 'care', 'unit', '(', 'icu', ')', 'stay', 'are', 'referred', 'to', 'as', 'post-intensive', 'care', 'syndrome', '(', 'pics', ')', '.', 'pics', 'has', 'not', 'been', 'described', 'in', 'older', 'adults', 'receiving', 'home', 'care', '.', 'our', 'aim', 'was', 'to', 'examine', 'the', 'relationship', 'between', 'length', 'of', 'icu', 'stay', 'and', 'pics', 'among', 'older', 'adults', 'receiving', 'home', 'care', '.', 'we', 'expected', 'that', 'patients', 'in', 'the', 'icu', 'for', '3', 'days', 'or', 'longer', 'would', 'demonstrate', 'significantly', 'more', 'disability', 'in', 'all', 'three', 'domains', 'on', 'follow-up', 'than', 'those', 'not', 'in', 'the', 'icu', '.', 'a', 'secondary', 'aim', 'was', 'to', 'identify', 'patient', 'characteristics', 'increasing', 'the', 'odds', 'of', 'disability', '.', 'design', ':', 'retrospective', 'cohort', 'study', '.', 'setting', ':', 'hospitalization', 'for', 'sepsis', 'in', 'the', 'united', 'states', '.', 'participants', ':', 'a', 'total', 'of', '21', '520', 'medicare', 'patients', 'receiving', 'home', 'care', 'and', 'reassessed', 'a', 'median', 'of', '1', 'day', '(', 'interquartile', 'range', '1-2', 'd', ')', 'after', 'hospital', 'discharge', '.', 'measurements', ':', 'pics', 'was', 'defined', 'as', 'a', 'decline', 'or', 'worsening', 'in', 'one', 'or', 'more', 'of', '16', 'indicators', 'tested', 'before', 'and', 'after', 'hospitalization', 'using', 'oasis', '(', 'home', 'health', 'outcome', 'and', 'assessment', 'information', 'set', ')', 'and', 'medicare', 'claims', 'data', '.', 'results', ':', 'the', 'sample', 'was', 'predominantly', 'female', 'and', 'white', '.', 'all', 'had', 'sepsis', ',', 'and', 'most', '(', '81.8', '%', ')', 'had', 'severe', 'sepsis', '.', 'in', 'adjusted', 'models', ',', 'an', 'icu', 'stay', 'of', '3', 'days', 'or', 'longer', ',', 'compared', 'with', 'no', 'icu', 'stay', ',', 'increased', 'the', 'odds', 'of', 'physical', 'disability', '.', 'overall', ',', 'the', 'declines', 'were', 'modest', 'and', 'found', 'in', 'specific', 'activities', 'of', 'daily', 'living', '(', '16', '%', 'for', 'feeding', 'and', 'lower', 'body', 'dressing', 'to', '26', '%', 'for', 'oral', 'medicine', 'management', ')', '.', 'no', 'changes', 'were', 'identified', 'in', 'cognition', 'or', 'mental', 'health', '.', 'significant', 'determinants', 'of', 'new', 'or', 'worsened', 'physical', 'disabilities', 'were', 'sepsis', 'severity', ',', 'older', 'age', ',', 'depression', ',', 'frailty', ',', 'and', 'dementia', '.', 'conclusion', ':', 'older', 'adults', 'receiving', 'home', 'care', 'who', 'develop', 'sepsis', 'and', 'are', 'in', 'an', 'icu', 'for', '3', 'days', 'or', 'longer', 'are', 'likely', 'to', 'develop', 'new', 'or', 'worsened', 'physical', 'disabilities', '.', 'whether', 'these', 'disabilities', 'remain', 'after', 'the', 'early', 'postdischarge', 'phase', 'requires', 'further', 'study', '.'], ['revitalizing', 'aging', 'skin', 'through', 'diet.mechanisms', 'underlying', 'aging', 'of', 'the', 'skin', 'dermis', 'are', 'poorly', 'understood', '.', 'now', ',', 'two', 'studies', '(', 'marsh', 'et', 'al.', ',', '2018', ';', 'salzer', 'et', 'al.', ',', '2018', ')', 'describe', 'complementary', 'approaches', 'to', 'this', 'question', ':', 'salzer', 'et', 'al', '.', 'show', 'that', 'aging', 'dermal', 'fibroblasts', 'lose', 'defined', 'identity', 'in', 'a', 'diet-influenced', 'fashion', ',', 'and', 'marsh', 'et', 'al', '.', 'reveal', 'that', 'fibroblast', 'loss', 'over', 'time', 'is', 'compensated', 'by', 'membrane', 'expansion', 'rather', 'than', 'proliferation', ',', 'resulting', 'in', 'decreased', 'cellular', 'density', '.'], ['a', 'partially', 'structured', 'postoperative', 'handoff', 'protocol', 'improves', 'communication', 'in', '2', 'mixed', 'surgical', 'intensive', 'care', 'units', ':', 'findings', 'from', 'the', 'handoffs', 'and', 'transitions', 'in', 'critical', 'care', '(', 'hatricc', ')', 'prospective', 'cohort', 'study.objective', ':', 'to', 'assess', 'the', 'effectiveness', 'of', 'standardizing', 'operating', 'room', '(', 'or', ')', 'to', 'intensive', 'care', 'unit', '(', 'icu', ')', 'handoffs', 'in', 'a', 'mixed', 'surgical', 'population', '.', 'summary', 'of', 'background', 'data', ':', 'standardizing', 'or', 'to', 'icu', 'handoffs', 'improves', 'information', 'transfer', 'after', 'cardiac', 'surgery', ',', 'but', 'there', 'is', 'limited', 'evidence', 'in', 'other', 'surgical', 'contexts', '.', 'methods', ':', 'this', 'prospective', 'interventional', 'cohort', 'study', '(', 'nct02267174', ')', 'was', 'conducted', 'in', '2', 'surgical', 'icus', 'in', '2', 'affiliated', 'hospitals', '.', 'from', '2014', 'to', '2016', ',', 'we', 'developed', ',', 'implemented', ',', 'and', 'assessed', 'the', 'effectiveness', 'of', 'a', 'new', 'standardized', 'handoff', 'protocol', 'requiring', 'bedside', 'clinician', 'communication', 'using', 'an', 'information', 'template', '.', 'the', 'primary', 'study', 'outcome', 'was', 'number', 'of', 'information', 'omissions', 'out', 'of', '13', 'possible', 'topics', ',', 'recorded', 'by', 'trained', 'observers', '.', 'data', 'were', 'analyzed', 'using', 'descriptive', 'statistics', ',', 'bivariate', 'analyses', ',', 'and', 'multivariable', 'regression', '.', 'results', ':', 'we', 'observed', '165', 'patient', 'transfers', '(', '68', 'pre-', ',', '97', 'postintervention', ')', '.', 'before', 'standardization', ',', 'observed', 'handoffs', 'had', 'a', 'mean', '4.7', '+/-', '2.9', 'information', 'omissions', 'each', '.', 'after', 'standardization', ',', 'information', 'omissions', 'decreased', '21.3', '%', 'to', '3.7', '+/-', '1.9', '(', 'p', '=', '0.023', ')', '.', 'in', 'a', 'pre-specified', 'subanalysis', ',', 'information', 'omissions', 'for', 'new', 'icu', 'patients', 'decreased', '36.2', '%', 'from', '4.7', '+/-', '3.1', 'to', '3.0', '+/-', '1.6', '(', 'p', '=', '0.008', ',', 'interaction', 'term', 'p', '=', '0.008', ')', '.', 'the', 'decrement', 'in', 'information', 'omissions', 'was', 'linearly', 'associated', 'with', 'the', 'number', 'of', 'protocol', 'steps', 'followed', '(', 'p', '<', '0.001', ')', '.', 'after', 'controlling', 'for', 'patient', 'stability', ',', 'the', 'intervention', 'was', 'still', 'associated', 'with', 'reduced', 'omissions', '.', 'handoff', 'duration', 'increased', 'after', 'standardization', 'from', '4.1', '+/-', '3.3', 'to', '8.0', '+/-', '3.9', 'minutes', '(', 'p', '<', '0.001', ')', '.', 'icu', 'mortality', 'and', 'length', 'of', 'stay', 'did', 'not', 'change', 'postimplementation', '.', 'conclusion', ':', 'standardizing', 'or', 'to', 'icu', 'handoffs', 'significantly', 'improved', 'information', 'exchange', 'in', '2', 'mixed', 'surgical', 'icus', ',', 'with', 'a', 'concomitant', 'increase', 'in', 'handoff', 'duration', '.', 'additional', 'research', 'is', 'needed', 'to', 'identify', 'barriers', 'to', 'and', 'facilitators', 'of', 'handoff', 'protocol', 'adherence', '.'], ['automated', 'data', 'extraction', 'and', 'ensemble', 'methods', 'for', 'predictive', 'modeling', 'of', 'breast', 'cancer', 'outcomes', 'after', 'radiation', 'therapy.purpose', ':', 'to', 'compare', 'the', 'effectiveness', 'of', 'ensemble', 'methods', '(', 'e.g', '.', 'random', 'forests', ')', 'and', 'single-model', 'methods', '(', 'e.g', '.', 'logistic', 'regression', 'and', 'decision', 'trees', ')', 'in', 'predictive', 'modeling', 'of', 'post-rt', 'treatment', 'failure', 'and', 'adverse', 'events', '(', 'aes', ')', 'for', 'breast', 'cancer', 'patients', 'using', 'automatically', 'extracted', 'emr', 'data', '.', 'methods', ':', 'data', 'from', '1,967', 'consecutive', 'breast', 'radiotherapy', '(', 'rt', ')', 'courses', 'at', 'one', 'institution', 'between', '2008-2015', 'was', 'automatically', 'extracted', 'from', 'emrs', 'and', 'oncology', 'information', 'systems', 'using', 'extraction', 'software', '.', 'over', '230', 'variables', 'were', 'extracted', 'spanning', 'the', 'following', 'variable', 'segments', ':', 'patient', 'demographics', ',', 'medical/surgical', 'history', ',', 'tumor', 'characteristics', ',', 'rt', 'treatment', 'history', ',', 'and', 'aes', 'tracked', 'using', 'ctcaev4.0', '.', 'treatment', 'failure', 'was', 'extracted', 'algorithmically', 'by', 'searching', 'post-treatment', 'encounters', 'for', 'evidence', 'of', 'local', ',', 'nodal', ',', 'or', 'distant', 'failure', '.', 'individual', 'models', 'were', 'trained', 'using', 'decision', 'trees', ',', 'logistic', 'regression', ',', 'random', 'forests', ',', 'and', 'boosted', 'decision', 'trees', 'to', 'predict', 'treatment', 'failures', 'and', 'aes', '.', 'models', 'were', 'fit', 'on', '75', '%', 'of', 'the', 'data', 'and', 'evaluated', 'for', 'probability', 'calibration', 'and', 'area', 'under', 'the', 'roc', 'curve', '(', 'auc', ')', 'on', 'the', 'remaining', 'test', 'set', '.', 'the', 'impact', 'of', 'each', 'variable', 'segment', 'was', 'assessed', 'by', 're-training', 'without', 'the', 'segment', 'and', 'measuring', 'change', 'in', 'auc', '(', 'deltaauc', ')', '.', 'results', ':', 'all', 'auc', 'values', 'were', 'statistically', 'significant', '(', 'p', '<', '0.05', ')', '.', 'ensemble', 'methods', 'outperformed', 'single-model', 'methods', 'across', 'all', 'outcomes', '.', 'the', 'best', 'ensemble', 'method', 'outperformed', 'decision', 'trees', 'and', 'logistic', 'regression', 'by', 'an', 'average', 'auc', 'of', '0.053', 'and', '0.034', ',', 'respectively', '.', 'model', 'probabilities', 'were', 'well-calibrated', 'as', 'evidenced', 'by', 'calibration', 'curves', '.', 'excluding', 'the', 'patient', 'medical', 'history', 'variable', 'segment', 'led', 'to', 'the', 'largest', 'auc', 'reduction', 'in', 'all', 'models', '(', 'average', 'deltaauc=', '-0.025', ')', ',', 'followed', 'by', 'rt', 'treatment', 'history', '(', '-0.021', ')', 'and', 'tumor', 'information', '(', '-0.015', ')', '.', 'conclusion', ':', 'in', 'this', 'largest', 'such', 'study', 'in', 'breast', 'cancer', 'performed', 'to', 'date', ',', 'automatically', 'extracted', 'emr', 'data', 'provided', 'a', 'basis', 'for', 'reliable', 'outcome', 'predictions', 'across', 'multiple', 'statistical', 'methods', '.', 'ensemble', 'methods', 'provided', 'substantial', 'advantages', 'over', 'single-model', 'methods', '.', 'patient', 'medical', 'history', 'contributed', 'the', 'most', 'to', 'prediction', 'quality', '.', 'this', 'article', 'is', 'protected', 'by', 'copyright', '.', 'all', 'rights', 'reserved', '.'], ['modeling', 'epidermal', 'growth', 'factor', 'inhibitor-mediated', 'enhancement', 'of', 'photodynamic', 'therapy', 'efficacy', 'using', '3d', 'mesothelioma', 'cell', 'culture.we', 'have', 'demonstrated', 'that', 'lung', 'sparing', 'surgery', 'with', 'intraoperative', 'photodynamic', 'therapy', '(', 'pdt', ')', 'achieves', 'remarkably', 'extended', 'survival', 'for', 'patients', 'with', 'malignant', 'pleural', 'mesothelioma', '(', 'mpm', ')', '.', 'nevertheless', ',', 'most', 'patients', 'treated', 'using', 'this', 'approach', 'experience', 'local', 'recurrence', ',', 'so', 'it', 'is', 'essential', 'to', 'identify', 'ways', 'to', 'enhance', 'tumor', 'response', '.', 'we', 'previously', 'reported', 'that', 'pdt', 'transiently', 'activates', 'egfr/stat3', 'in', 'lung', 'and', 'ovarian', 'cancer', 'cells', 'and', 'inhibiting', 'egfr', 'via', 'erlotinib', 'can', 'increase', 'pdt', 'sensitivity', '.', 'additionally', ',', 'we', 'have', 'seen', 'higher', 'egfr', 'expression', 'associating', 'with', 'worse', 'outcomes', 'after', 'photofrin-mediated', 'pdt', 'for', 'mpm', ',', 'and', 'the', 'extensive', 'desmoplastic', 'reaction', 'associated', 'with', 'mpm', 'influences', 'tumor', 'phenotype', 'and', 'therapeutic', 'response', '.', 'since', 'extracellular', 'matrix', '(', 'ecm', ')', 'proteins', 'accrued', 'during', 'stroma', 'development', 'can', 'alter', 'egf', 'signaling', 'within', 'tumors', ',', 'we', 'have', 'characterized', 'novel', '3d', 'models', 'of', 'mpm', 'to', 'determine', 'their', 'response', 'to', 'erlotinib', 'combined', 'with', 'photofrin-pdt', '.', 'our', 'mpm', 'cell', 'lines', 'formed', 'a', 'range', 'of', 'acinar', 'phenotypes', 'when', 'grown', 'on', 'ecm', 'gels', ',', 'recapitulating', 'the', 'locally', 'invasive', 'phenotype', 'of', 'mpm', 'in', 'pleura', 'and', 'endothoracic', 'fascia', '.', 'using', 'these', 'models', ',', 'we', 'confirmed', 'that', 'egfr', 'inhibition', 'increases', 'pdt', 'cytotoxicity', '.', 'together', 'with', 'emerging', 'evidence', 'that', 'egfr', 'inhibition', 'may', 'improve', 'survival', 'of', 'lung', 'cancer', 'patients', 'through', 'immunologic', 'and', 'direct', 'cell', 'killing', 'mechanisms', ',', 'these', 'results', 'suggest', 'erlotinib-enhanced', 'pdt', 'may', 'significantly', 'improve', 'outcomes', 'for', 'mpm', 'patients', '.', 'this', 'article', 'is', 'protected', 'by', 'copyright', '.', 'all', 'rights', 'reserved', '.']]\n"
     ]
    }
   ],
   "source": [
    "gen_docs = [[w.lower() for w in word_tokenize(text)] \n",
    "            for text in raw_documents.text]\n",
    "print(gen_docs[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "6152\n",
      "Number of words in dictionary: 82783\n"
     ]
    }
   ],
   "source": [
    "# create a dictionary to match tokens to integers\n",
    "dictionary = gensim.corpora.Dictionary(gen_docs)\n",
    "print(dictionary[5])\n",
    "print(dictionary.token2id['road'])\n",
    "print(\"Number of words in dictionary:\",len(dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lists the number of times each word occurs in the document\n",
    "# list of tuples\n",
    "    # first = index of the word\n",
    "    # second = number of time that appears in that document\n",
    "corpus = [dictionary.doc2bow(gen_doc) for gen_doc in gen_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of unique tokens in the first document\n",
    "len(corpus[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "term frequency inverse term frequency (tf-idf):\n",
    "    term frequency = how often a word shows up in a document\n",
    "    inverse document frequency = scale that value by how rare the word is in the corpus\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfModel(num_docs=8367, num_nnz=1237181)\n",
      "1237181\n"
     ]
    }
   ],
   "source": [
    "tf_idf = gensim.models.TfidfModel(corpus)\n",
    "print(tf_idf)\n",
    "s = 0\n",
    "for i in corpus:\n",
    "    s += len(i)\n",
    "print(s)\n",
    "# num_nnz = number of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = gensim.similarities.Similarity(str(similarities_path),\n",
    "                                       tf_idf[corpus], \n",
    "                                       num_features=len(dictionary)) \n",
    "query = next(iter(corpus))\n",
    "result = index[query]  # search similar to `query` in index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document = 0, pmid = 30500988\n",
      "document = 1, pmid = 30500532\n"
     ]
    }
   ],
   "source": [
    "# yield similarities of the indexed documents\n",
    "with Path(similarities_path, 'document_0_50.txt').open('w+') as out_file:\n",
    "    writer = csv.writer(out_file, delimiter=',')\n",
    "    for doc_sim_ix, doc_sim in enumerate(index):\n",
    "        if doc_sim_ix == 51:\n",
    "            break\n",
    "        pmid = raw_documents.loc[doc_sim_ix]['pmid']\n",
    "        c_doc = 'document = {0}, pmid = {1}'.format(doc_sim_ix, pmid)\n",
    "        print(c_doc)\n",
    "        writer.writerow([pmid])\n",
    "        writer.writerow(list(enumerate(sim_result)))\n",
    "        out_file.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
